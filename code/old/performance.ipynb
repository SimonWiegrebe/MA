{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c450a0d",
   "metadata": {},
   "source": [
    "### app-level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901dfcad",
   "metadata": {},
   "source": [
    "##### exact prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893651aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_by_cat_exact = pd.DataFrame()\n",
    "# for cat in cat_counts.index:\n",
    "#     pred_cat = predictions[predictions['ground_truth_category_name'] == cat]\n",
    "#     df = pd.DataFrame()\n",
    "#     df['category'] = [cat]\n",
    "#     count = cat_counts[cat]\n",
    "#     df['count'] = [count]\n",
    "#     for algo in algorithms:\n",
    "#         algo_name = ''.join(algo.split('-')[1:])\n",
    "#         value = pred_cat.apply(lambda x: calc_hr_k(x['ground_truth'], x[algo], k), axis=1).sum()/len(pred_cat)\n",
    "#         df[algo_name] = [value]\n",
    "#     perf_by_cat_exact = perf_by_cat_exact.append(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5471299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_by_cat_exact.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee743c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for algo in perf_by_cat_exact.columns[2:]:\n",
    "#     row = perf_by_cat_exact[algo].argmax()\n",
    "#     cat = perf_by_cat_exact['category'][row]\n",
    "#     perf = perf_by_cat_exact[algo][row]\n",
    "#     count = perf_by_cat_exact['count'][row]\n",
    "#     print('algo ' + str(algo) + ': best performance for category ' + str(cat) + '(freq: ' + str(count) + '): HR@' + str(k) + ' ' + str(perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb768945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_by_cat_cat = pd.DataFrame()\n",
    "# for cat in cat_counts.index:\n",
    "#     pred_cat = predictions[predictions['ground_truth_category_name'] == cat]\n",
    "#     df = pd.DataFrame()\n",
    "#     df['category'] = [cat]\n",
    "#     count = cat_counts[cat]\n",
    "#     df['count'] = [count]\n",
    "#     for algo in algorithms_names:\n",
    "#         col_name = 'recs_names_cat-' + ''.join(algo.split('-')[1:])\n",
    "#         algo_name = ''.join(algo.split('-')[1:])\n",
    "#         value = pred_cat.apply(lambda x: calc_hr_k(x['ground_truth_category_name'], x[col_name], k), axis=1).sum()/len(pred_cat)\n",
    "#         df[algo_name] = [value]\n",
    "#     perf_by_cat_cat = perf_by_cat_cat.append(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_by_cat_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecf1ba",
   "metadata": {},
   "source": [
    "### sequence-level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5db80",
   "metadata": {},
   "source": [
    "##### extracting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create app and user mappings\n",
    "data = pd.read_csv('../../data/sequence-level/data_seq.csv')\n",
    "\n",
    "mapping = dict([(y,x+1) for x,y in enumerate(sorted(set(data['category_list'])))])\n",
    "mapping_reverse = dict((v,k) for k,v in mapping.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract ground truth from test data (test_data) for a single item (position) in a single session (sessionId)\n",
    "def extract_ground_truth(ID, position, test_data):\n",
    "    relevant_df = test_data[test_data[SESSION_KEY]==ID]\n",
    "    index = relevant_df.index[position+1]\n",
    "    ground_truth = relevant_df[ITEM_KEY][index]\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd253ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_files = [f for f in os.listdir(path_results) if 'Saver' in f]\n",
    "predictions = pd.DataFrame()\n",
    "for file in predictions_files:\n",
    "    model = \"_\".join(file.split('_')[2:-1])\n",
    "    df = pd.read_csv(path_results + file, sep = ';')\n",
    "    if 'sessionID' not in predictions.columns:\n",
    "        predictions['sessionID'] = df['SessionId']\n",
    "    if 'position' not in predictions.columns:\n",
    "        predictions['position'] = df['Position']\n",
    "    if 'ground_truth' not in predictions.columns:\n",
    "        predictions['ground_truth'] = predictions.apply(lambda x: extract_ground_truth(x['sessionID'], x['position'], test_data), axis=1)\n",
    "        predictions['ground_truth_name'] = predictions['ground_truth'].apply(lambda x: mapping_reverse[x])\n",
    "    predictions['recs-' + model] = df['Recommendations'].apply(lambda x: [int(i) for i in x.split(',')])\n",
    "    predictions['recs_names-' + model] = predictions['recs-' + model].apply(lambda x: [mapping_reverse[i] for i in x])\n",
    "    predictions['scores-' + model] = df['Scores'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba345fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(predictions, sessionID, num_recs, models):\n",
    "    # predictions must contain columns named 'sessionID' and 'position', containing the respective values\n",
    "    predictions_dict = {}\n",
    "    for pos in positions:\n",
    "        row = predictions[(predictions.sessionID == sessionID) & (predictions.position == pos)]\n",
    "        ground_truth = row.ground_truth_name.to_string(index=False)\n",
    "#         print('sessionID: ' + str(sessionID) + ', position: ' + str(pos))\n",
    "#         print('ground truth: ' + str(row.ground_truth_name.to_string(index=False)))\n",
    "        df = pd.DataFrame()\n",
    "        for model in models:\n",
    "            df[model] = [row['recs_names-' + model].tolist()[0][i] for i in range(num_recs)]\n",
    "        name = str(sessionID) + '_' + str(pos)\n",
    "        predictions_dict[name] = (sessionID, pos, ground_truth, df)\n",
    "    return predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionID = predictions.sessionID.unique()[0]\n",
    "num_recs = 5\n",
    "positions = predictions.position[predictions.sessionID==sessionID]\n",
    "models = results.model.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predictions(predictions, sessionID, num_recs, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78550584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.apply(lambda x: x['recs-sr_B'][0] == x['ground_truth'], axis=1).sum()/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582a046",
   "metadata": {},
   "source": [
    "##### performance by positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49375694",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [i for i in predictions.columns if i.startswith('recs-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function outputting whether ground truth is in recommendation list of length k for a single algorithm and item\n",
    "def calc_hr_k(ground_truth, rec_list, k):\n",
    "    return ground_truth in rec_list[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fe648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts = predictions['position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad54312",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_by_pos = pd.DataFrame()\n",
    "for pos in pos_counts.index:\n",
    "    pred_pos = predictions[predictions['position']==pos]\n",
    "    df = pd.DataFrame()\n",
    "    df['position'] = [pos]\n",
    "    count = pos_counts[pos]\n",
    "    df['count'] = [count]\n",
    "    for algo in algorithms:\n",
    "        algo_name = ''.join(algo.split('-')[1:])\n",
    "        value = pred_pos.apply(lambda x: calc_hr_k(x['ground_truth'], x[algo], k), axis=1).sum()/len(pred_pos)\n",
    "        df[algo_name] = [value]\n",
    "    perf_by_pos = perf_by_pos.append(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_by_pos.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf517df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering only positions <= vs. >\n",
    "perf_by_pos = pd.DataFrame()\n",
    "cutoff = 5\n",
    "for pos in ['<=', '>']:\n",
    "    if pos=='<=':\n",
    "        pred_pos = predictions[predictions['position']<=cutoff]\n",
    "    else:\n",
    "        pred_pos = predictions[predictions['position']>cutoff]\n",
    "    df = pd.DataFrame()\n",
    "    df['position'] = [pos]\n",
    "    for algo in algorithms:\n",
    "        algo_name = ''.join(algo.split('-')[1:])\n",
    "        value = pred_pos.apply(lambda x: calc_hr_k(x['ground_truth'], x[algo], k), axis=1).sum()/len(pred_pos)\n",
    "        df[algo_name] = [value]\n",
    "    perf_by_pos = perf_by_pos.append(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb307ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_by_pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
