{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7f6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = \"gru4rec_Reminder\"\n",
    "budget = 100\n",
    "windows = [1,2,3,4,5]\n",
    "window = windows[0]\n",
    "cmd_list = [[\"python\", \"conf/in/\" + str(algo) + \"-config_\" + str(i) + \"-window_\" + str(window) + \".yml\"] for i in range(budget)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911875f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df80ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = theano.tensor.ivector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db44dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = T.ivector()\n",
    "new_r = T.set_subtensor(r[10:], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912d6d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncSubtensor{Set;int64::}.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766e2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4af70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_life_universe_everything(x):\n",
    "    answer = 42\n",
    "    \n",
    "    answer += x\n",
    "    set_trace()\n",
    "    return answer\n",
    "\n",
    "# add_to_life_universe_everything(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c6dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-7-ec0c16a426ff>\u001b[0m(6)\u001b[0;36madd_to_life_universe_everything\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      4 \u001b[1;33m    \u001b[0manswer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 6 \u001b[1;33m    \u001b[1;32mreturn\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m\u001b[1;31m# add_to_life_universe_everything(12)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x\n",
      "12\n",
      "ipdb> continue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_to_life_universe_everything(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac541be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "if True:\n",
    "    path1 = Path(r'path/to/file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8111560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "import socket\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from _datetime import timezone, datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837dbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = '../../bert4rec_3/data/ml-1mSimon.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684bd28e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-90a303a92978>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../bert4rec_3/data/ml-1mSimon.vocab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vocab'"
     ]
    }
   ],
   "source": [
    "with open('../../bert4rec_3/data/ml-1mSimon.vocab', 'rb') as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48d59f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ea0f4d7dd9bd>:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  conf = yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "stream = open('../../session-aware_rc_2020/code/conf/retailrocket_sa.yml')\n",
    "conf = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc878668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class(path):\n",
    "    '''\n",
    "    Load a class from the path in the configuration\n",
    "        --------\n",
    "        path : dict of dicts\n",
    "            Path to the class, e.g., algorithms.knn.cknn.ContextKNNN\n",
    "    '''\n",
    "    module_name, class_name = path.rsplit('.', 1)\n",
    "\n",
    "    Class = getattr(importlib.import_module(module_name), class_name)\n",
    "    return Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "640aa7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'algorithm.'+'baselines.sr.SequentialRules'\n",
    "module_name, class_name = path.rsplit('.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65352dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_algorithms_dict(list):\n",
    "    '''\n",
    "    Create algorithm instances from the list of algorithms in the configuration\n",
    "        --------\n",
    "        list : list of dicts\n",
    "            Dicts represent a single algorithm with class, a key, and optionally a param dict\n",
    "    '''\n",
    "\n",
    "    algorithms = {}\n",
    "    for algorithm in list:\n",
    "        Class = SequentialRules\n",
    "\n",
    "        default_params = algorithm['params'] if 'params' in algorithm else {}\n",
    "        random_params = {}\n",
    "        params = {**default_params, **random_params}\n",
    "        del default_params, random_params\n",
    "\n",
    "#         if 'params' in algorithm:\n",
    "#             if 'algorithms' in algorithm['params']:\n",
    "#                 hybrid_algorithms = create_algorithms_dict(algorithm['params']['algorithms'])\n",
    "#                 params['algorithms'] = []\n",
    "#                 a_keys = []\n",
    "#                 for k, a in hybrid_algorithms.items():\n",
    "#                     params['algorithms'].append(a)\n",
    "#                     a_keys.append(k)\n",
    "\n",
    "        # instance = Class( **params )\n",
    "        key = algorithm['key'] if 'key' in algorithm else algorithm['class']\n",
    "        if 'params' in algorithm:\n",
    "            if 'algorithms' in algorithm['params']:\n",
    "                for k, val in params.items():\n",
    "                    if k == 'algorithms':\n",
    "                        for pKey in a_keys:\n",
    "                            key += '-' + pKey\n",
    "                    elif k == 'file':\n",
    "                        key += ''\n",
    "                    else:\n",
    "                        key += '-' + str(k) + \"=\" + str(val)\n",
    "                        key = key.replace(',', '_')\n",
    "\n",
    "            else:\n",
    "                for k, val in params.items():\n",
    "                    if k != 'file':\n",
    "                        key += '-' + str(k) + \"=\" + str(val)\n",
    "                        key = key.replace(',', '_')\n",
    "                    # key += '-' + '-'.join( map( lambda x: str(x[0])+'='+str(x[1]), params.items() ) )\n",
    "\n",
    "        if 'params_var' in algorithm:\n",
    "            for k, var in algorithm['params_var'].items():\n",
    "                for val in var:\n",
    "                    params[k] = val  # params.update({k: val})\n",
    "                    kv = k\n",
    "                    for v in val:\n",
    "                        kv += '-' + str(v)\n",
    "                    instance = Class(**params)\n",
    "                    algorithms[key + kv] = instance\n",
    "        else:\n",
    "            instance = Class(**params)\n",
    "            algorithms[key] = instance\n",
    "\n",
    "    return algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adb5f785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'baselines.sr.SequentialRules',\n",
       "  'params': {'steps': 20, 'weighting': 'quadratic'},\n",
       "  'key': 'sr'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [conf['algorithms'][0]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2aba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = create_algorithms_dict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ba05ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('sr-steps=20-weighting=quadratic', <__main__.SequentialRules object at 0x0000027612E1F730>)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232cccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_algorithm(train, test, key, algorithm, eval, metrics, results, conf, slice=None, iteration=None, out=True):\n",
    "    '''\n",
    "    Evaluate one single algorithm\n",
    "        --------\n",
    "        train : Dataframe\n",
    "            Training data\n",
    "        test: Dataframe\n",
    "            Test set\n",
    "        key: string\n",
    "            The automatically created key string for the algorithm\n",
    "        algorithm: algorithm object\n",
    "            Just the algorithm object, e.g., ContextKNN\n",
    "        eval: module\n",
    "            The module for evaluation, e.g., evaluation.evaluation_last\n",
    "        metrics: list of Metric\n",
    "            Optional string to add to the file name\n",
    "        results: dict\n",
    "            Result dictionary\n",
    "        conf: dict\n",
    "            Configuration dictionary\n",
    "        slice: int\n",
    "            Optional index for the window slice\n",
    "    '''\n",
    "    ts = time.time()\n",
    "    print('fit ', key)\n",
    "    # send_message( 'training algorithm ' + key )\n",
    "\n",
    "    if hasattr(algorithm, 'init'):\n",
    "        algorithm.init(train, test, slice=slice)\n",
    "\n",
    "    for m in metrics:\n",
    "        if hasattr(m, 'start'):\n",
    "            m.start(algorithm)\n",
    "\n",
    "    algorithm.fit(train, test)\n",
    "    print(key, ' time: ', (time.time() - ts))\n",
    "\n",
    "    if 'results' in conf and 'pickle_models' in conf['results']:\n",
    "        try:\n",
    "            save_model(key, algorithm, conf)\n",
    "        except Exception:\n",
    "            print('could not save model for ' + key)\n",
    "\n",
    "    for m in metrics:\n",
    "        if hasattr(m, 'start'):\n",
    "            m.stop(algorithm)\n",
    "\n",
    "    results[key] = eval.evaluate_sessions(algorithm, metrics, test, train)\n",
    "    if out:\n",
    "        write_results_csv({key: results[key]}, conf, extra=key, iteration=iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec34c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = create_algorithms_dict(conf['algorithms'])\n",
    "    metrics = create_metric_list(conf['metrics'])\n",
    "    evaluation = load_evaluation(conf['evaluation'])\n",
    "\n",
    "    buys = pd.DataFrame()\n",
    "\n",
    "    if 'type' in conf['data']:\n",
    "        if conf['data']['type'] == 'hdf':  # hdf5 file\n",
    "            if 'opts' in conf['data']:\n",
    "                # ( path, file, sessions_train=None, sessions_test=None, slice_num=None, train_eval=False )\n",
    "                train, test = dl.load_data_session_hdf(conf['data']['folder'], conf['data']['prefix'], slice_num=slice,\n",
    "                                                       **conf['data']['opts'])\n",
    "            else:\n",
    "                train, test = dl.load_data_session_hdf(conf['data']['folder'], conf['data']['prefix'], slice_num=slice)\n",
    "        # elif conf['data']['type'] == 'csv': # csv file\n",
    "    else:  # csv file (default)\n",
    "        if 'opts' in conf['data']:\n",
    "            train, test = dl.load_data_session(conf['data']['folder'], conf['data']['prefix'], slice_num=slice,\n",
    "                                               **conf['data']['opts'])\n",
    "        else:\n",
    "            train, test = dl.load_data_session(conf['data']['folder'], conf['data']['prefix'], slice_num=slice)\n",
    "        if 'buys' in conf['data'] and 'file_buys' in conf['data']:\n",
    "            buys = dl.load_buys(conf['data']['folder'], conf['data']['file_buys'])  # load buy actions in addition\n",
    "    # else:\n",
    "    #     raise RuntimeError('Unknown data type: {}'.format(conf['data']['type']))\n",
    "\n",
    "    for m in metrics:\n",
    "        m.init(train)\n",
    "        if hasattr(m, 'set_buys'):\n",
    "            m.set_buys(buys, test)\n",
    "\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03872a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a in algorithms.items():\n",
    "        eval_algorithm(train, test, k, a, evaluation, metrics, results, conf, slice=slice, iteration=slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ecf8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(train, test):\n",
    "    if 'ItemId' in train.columns and 'SessionId' in train.columns:\n",
    "\n",
    "        new_in_test = set(test.ItemId.unique()) - set(train.ItemId.unique())\n",
    "        if len(new_in_test) > 0:\n",
    "            print('WAAAAAARRRNIIIIING: new items in test set')\n",
    "\n",
    "        session_min_train = train.groupby('SessionId').size().min()\n",
    "        if session_min_train == 0:\n",
    "            print('WAAAAAARRRNIIIIING: session length 1 in train set')\n",
    "\n",
    "        session_min_test = test.groupby('SessionId').size().min()\n",
    "        if session_min_test == 0:\n",
    "            print('WAAAAAARRRNIIIIING: session length 1 in train set')\n",
    "\n",
    "        sess_train = train.SessionId.unique()\n",
    "        sess_test = test.SessionId.unique()\n",
    "\n",
    "        if not all(sess_train[i] <= sess_train[i + 1] for i in range(len(sess_train) - 1)):\n",
    "            print('WAAAAAARRRNIIIIING: train sessions not sorted by id')\n",
    "            train.sort_values(['SessionId', 'Time'], inplace=True)\n",
    "            print(' -- corrected the order')\n",
    "\n",
    "        if not all(sess_test[i] <= sess_test[i + 1] for i in range(len(sess_test) - 1)):\n",
    "            print('WAAAAAARRRNIIIIING: test sessions not sorted by id')\n",
    "            test.sort_values(['SessionId', 'Time'], inplace=True)\n",
    "            print(' -- corrected the order')\n",
    "\n",
    "        test.SessionId.unique()\n",
    "\n",
    "    else:\n",
    "        print('data check not possible due to individual column names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9bfe0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df): #TODO: handle this part daynamicly\n",
    "    names = {}\n",
    "    names['item_id'] = 'ItemId'\n",
    "    names['sessionId'] = 'SessionId'\n",
    "    names['user_id'] = 'UserId'\n",
    "    names['created_at'] = 'Time'\n",
    "\n",
    "    names['itemId'] = 'ItemId'\n",
    "    names['session_id'] = 'SessionId'\n",
    "    names['userId'] = 'UserId'\n",
    "    names['eventdate'] = 'Time'\n",
    "\n",
    "    names['itemid'] = 'ItemId'\n",
    "    names['session_id'] = 'SessionId'\n",
    "    names['visitorid'] = 'UserId'\n",
    "    names['timestamp'] = 'Time'\n",
    "\n",
    "    for col in list(df.columns):\n",
    "        if col in names:\n",
    "            df[names[col]] = df[col]\n",
    "            del df[col]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3e4fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_session(train, test, sessions_train=None, sessions_test=None):\n",
    "    train = rename_cols(train)\n",
    "    test = rename_cols(test)\n",
    "\n",
    "    if (sessions_train != None):\n",
    "        keep = train.sort_values('Time', ascending=False).SessionId.unique()[:(sessions_train - 1)]\n",
    "        train = train[np.in1d(train.SessionId, keep)]\n",
    "        test = test[np.in1d(test.ItemId, train.ItemId)]\n",
    "\n",
    "    if (sessions_test != None):\n",
    "        keep = test.SessionId.unique()[:(sessions_test - 1)]\n",
    "        test = test[np.in1d(test.SessionId, keep)]\n",
    "\n",
    "    session_lengths = test.groupby('SessionId').size()\n",
    "    test = test[np.in1d(test.SessionId, session_lengths[session_lengths > 1].index)]\n",
    "\n",
    "    # output\n",
    "    data_start = datetime.fromtimestamp(train.Time.min(), timezone.utc)\n",
    "    data_end = datetime.fromtimestamp(train.Time.max(), timezone.utc)\n",
    "\n",
    "    print('Loaded train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}\\n\\tSpan: {} / {}\\n'.\n",
    "          format(len(train), train.SessionId.nunique(), train.ItemId.nunique(), data_start.date().isoformat(),\n",
    "                 data_end.date().isoformat()))\n",
    "\n",
    "    data_start = datetime.fromtimestamp(test.Time.min(), timezone.utc)\n",
    "    data_end = datetime.fromtimestamp(test.Time.max(), timezone.utc)\n",
    "\n",
    "    print('Loaded test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}\\n\\tSpan: {} / {}\\n'.\n",
    "          format(len(test), test.SessionId.nunique(), test.ItemId.nunique(), data_start.date().isoformat(),\n",
    "                 data_end.date().isoformat()))\n",
    "\n",
    "    check_data(train, test)\n",
    "\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbaf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_session_hdf(path, file, sessions_train=None, sessions_test=None, slice_num=None,\n",
    "                          train_eval=False):\n",
    "    '''\n",
    "       [HDF5 format] Loads a tuple of training and test set with the given parameters.\n",
    "\n",
    "       Parameters\n",
    "       --------\n",
    "       path : string\n",
    "           Base path to look in for the prepared data files\n",
    "       file : string\n",
    "           Prefix of  the dataset you want to use.\n",
    "           \"yoochoose-clicks-full\" loads yoochoose-clicks-full_train_full.txt and yoochoose-clicks-full_test.txt\n",
    "       rows_train : int or None\n",
    "           Number of rows to load from the training set file.\n",
    "           This option will automatically filter the test set to only retain items included in the training set.\n",
    "       rows_test : int or None\n",
    "           Number of rows to load from the test set file.\n",
    "       slice_num :\n",
    "           Adds a slice index to the constructed file_path\n",
    "           yoochoose-clicks-full_train_full.0.txt\n",
    "       density : float\n",
    "           Percentage of the sessions to randomly retain from the original data (0-1).\n",
    "           The result is cached for the execution of multiple experiments.\n",
    "       Returns\n",
    "       --------\n",
    "       out : tuple of pandas.DataFrame\n",
    "           (train, test)\n",
    "\n",
    "       '''\n",
    "\n",
    "    print('START load data')\n",
    "\n",
    "    split = ''\n",
    "    if (slice_num != None and isinstance(slice_num, int)):\n",
    "        split = '.' + str(slice_num)\n",
    "\n",
    "    # train_appendix = '_train_full'\n",
    "    # test_appendix = '_test'\n",
    "    train_key = 'train'\n",
    "    test_key = 'test'\n",
    "    if train_eval:\n",
    "        # train_appendix = '_train_tr'\n",
    "        # test_appendix = '_train_valid'\n",
    "        train_key = 'valid_train'\n",
    "        test_key = 'valid_test'\n",
    "\n",
    "    # train = pd.read_csv(path + file + train_appendix + split + '.txt', sep='\\t', dtype={'ItemId': np.int64})\n",
    "    # test = pd.read_csv(path + file + test_appendix + split + '.txt', sep='\\t', dtype={'ItemId': np.int64})\n",
    "\n",
    "    sessions_path = os.path.join(path, file + split + '.hdf')\n",
    "    train = pd.read_hdf(sessions_path, train_key)\n",
    "    test = pd.read_hdf(sessions_path, test_key)\n",
    "\n",
    "    train, test = prepare_data_session(train, test, sessions_train,\n",
    "                                       sessions_test)  # (train, test, sessions_train=None, sessions_test=None)\n",
    "\n",
    "    print('!!!!!!!!! File: ' + file + split + '.hdf')\n",
    "\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50fda52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START load data\n",
      "Loaded train set\n",
      "\tEvents: 4311703\n",
      "\tSessions: 843986\n",
      "\tItems: 1739\n",
      "\tSpan: 2017-10-29 / 2018-01-22\n",
      "\n",
      "Loaded test set\n",
      "\tEvents: 1570\n",
      "\tSessions: 310\n",
      "\tItems: 131\n",
      "\tSpan: 2017-11-06 / 2018-01-22\n",
      "\n",
      "!!!!!!!!! File: events.hdf\n"
     ]
    }
   ],
   "source": [
    "a = load_data_session_hdf(path=\"../../session-aware_rc_2020/code/data/retailrocket/prepared/\", file=\"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c424c05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>1</td>\n",
       "      <td>1.514119e+09</td>\n",
       "      <td>1553</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>1</td>\n",
       "      <td>1.514119e+09</td>\n",
       "      <td>1553</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>1</td>\n",
       "      <td>1.514119e+09</td>\n",
       "      <td>1553</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>1</td>\n",
       "      <td>1.514119e+09</td>\n",
       "      <td>1553</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td>1</td>\n",
       "      <td>1.514119e+09</td>\n",
       "      <td>1553</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306580</th>\n",
       "      <td>309</td>\n",
       "      <td>1.513229e+09</td>\n",
       "      <td>842782</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306581</th>\n",
       "      <td>309</td>\n",
       "      <td>1.513229e+09</td>\n",
       "      <td>842782</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306582</th>\n",
       "      <td>309</td>\n",
       "      <td>1.513229e+09</td>\n",
       "      <td>842782</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314828</th>\n",
       "      <td>310</td>\n",
       "      <td>1.515953e+09</td>\n",
       "      <td>844296</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314829</th>\n",
       "      <td>310</td>\n",
       "      <td>1.515953e+09</td>\n",
       "      <td>844296</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId          Time  SessionId  ItemId\n",
       "9537          1  1.514119e+09       1553    1392\n",
       "9538          1  1.514119e+09       1553    1393\n",
       "9539          1  1.514119e+09       1553    1169\n",
       "9540          1  1.514119e+09       1553    1539\n",
       "9541          1  1.514119e+09       1553    1564\n",
       "...         ...           ...        ...     ...\n",
       "4306580     309  1.513229e+09     842782    1392\n",
       "4306581     309  1.513229e+09     842782    1181\n",
       "4306582     309  1.513229e+09     842782    1389\n",
       "4314828     310  1.515953e+09     844296    1392\n",
       "4314829     310  1.515953e+09     844296    1389\n",
       "\n",
       "[1570 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0066eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sessions(pr, metrics, test_data, train_data, items=None, session_key='SessionId',\n",
    "                                 user_key='UserId', item_key='ItemId', time_key='Time'):\n",
    "    \"\"\"\n",
    "    Evaluates the HGRU4Rec network wrt. recommendation accuracy measured by recall@N and MRR@N.\n",
    "    Concatenates train sessions to test sessions to bootstrap the hidden states of the HGRU.\n",
    "    The number of the last sessions of each user that are used in the bootstrapping is controlled by `bootstrap_length`.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    pr : gru4rec.HGRU4Rec\n",
    "        A trained instance of the HGRU4Rec network.\n",
    "    train_data : pandas.DataFrame\n",
    "        Train data. It contains the transactions of the test set. It has one column for session IDs,\n",
    "        one for item IDs and one for the timestamp of the events (unix timestamps).\n",
    "        It must have a header. Column names are arbitrary, but must correspond to the keys you use in this function.\n",
    "    test_data : pandas.DataFrame\n",
    "        Test data. Same format of train_data.\n",
    "    items : 1D list or None\n",
    "        The list of item ID that you want to compare the score of the relevant item to.\n",
    "        If None, all items of the training set are used. Default value is None.\n",
    "    cut_off : int\n",
    "        Cut-off value (i.e. the length of the recommendation list; N for recall@N and MRR@N). Default value is 20.\n",
    "    batch_size : int\n",
    "        Number of events bundled into a batch during evaluation. Speeds up evaluation.\n",
    "         If it is set high, the memory consumption increases. Default value is 100.\n",
    "    break_ties : boolean\n",
    "        Whether to add a small random number to each prediction value in order to break up possible ties,\n",
    "        which can mess up the evaluation.\n",
    "        Defaults to False, because (1) GRU4Rec usually does not produce ties, except when the output saturates;\n",
    "        (2) it slows down the evaluation.\n",
    "        Set to True is you expect lots of ties.\n",
    "    output_rankings: boolean\n",
    "        If True, stores the predicted ranks of every event in test data into a Pandas DataFrame\n",
    "        that is returned by this function together with the metrics.\n",
    "        Notice that predictors models do not provide predictions for the first event in each session. (default: False)\n",
    "    bootstrap_length: int\n",
    "        Number of sessions in train data used to bootstrap the hidden state of the predictor,\n",
    "        starting from the last training session of each user.\n",
    "        If -1, consider all sessions. (default: -1)\n",
    "    session_key : string\n",
    "        Header of the session ID column in the input file (default: 'SessionId')\n",
    "    user_key : string\n",
    "        Header of the user ID column in the input file (default: 'UserId')\n",
    "    item_key : string\n",
    "        Header of the item ID column in the input file (default: 'ItemId')\n",
    "    time_key : string\n",
    "        Header of the timestamp column in the input file (default: 'Time')\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    out : tuple\n",
    "        (Recall@N, MRR@N[, DataFrame with the detailed predicted ranks])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    actions = len(test_data)\n",
    "    sessions = len(test_data[session_key].unique())\n",
    "    count = 0\n",
    "    print('START evaluation of ', actions, ' actions in ', sessions, ' sessions')\n",
    "\n",
    "    sc = time.clock();\n",
    "    st = time.time();\n",
    "\n",
    "    time_sum = 0\n",
    "    time_sum_clock = 0\n",
    "    time_count = 0\n",
    "\n",
    "    for m in metrics:\n",
    "        m.reset();\n",
    "\n",
    "    # In case someone would try to run with both items=None and not None on the same model\n",
    "    # without realizing that the predict function needs to be replaced\n",
    "    # pr.predict = None\n",
    "\n",
    "    items_to_predict = train_data[item_key].unique()\n",
    "\n",
    "    # use the training sessions of the users in test_data to bootstrap the state of the user RNN\n",
    "    test_users = test_data[user_key].unique()\n",
    "    train_data = train_data[train_data[user_key].isin(test_users)].copy()\n",
    "\n",
    "    # concatenate training and test sessions\n",
    "    train_data['in_eval'] = False\n",
    "    test_data['in_eval'] = True\n",
    "    if pr.support_users(): # e.g. hgru4rec\n",
    "        if pr.predict_with_training_data():\n",
    "            test_data = pd.concat([train_data, test_data])\n",
    "\n",
    "    test_data.sort_values([user_key, session_key, time_key], inplace=True)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "    offset_sessions = np.zeros(test_data[session_key].nunique() + 1, dtype=np.int32)\n",
    "    length_session = np.zeros(test_data[session_key].nunique(), dtype=np.int32)\n",
    "    offset_sessions[1:] = test_data.groupby([user_key, session_key]).size().cumsum() # offset_sessions[1:] = test_data.groupby(session_key).size().cumsum()\n",
    "    length_session[0:] = test_data.groupby([user_key, session_key]).size() # length_session[0:] = test_data.groupby(session_key).size()\n",
    "\n",
    "    current_session_idx = 0\n",
    "    # pos: to iterate over test data to retrieve the current session and it's first interaction\n",
    "    pos = offset_sessions[current_session_idx] # index of the first element of the current session in the test data\n",
    "    position = 0  # position (index) of the current element in the current session\n",
    "    finished = False\n",
    "\n",
    "    prev_sid = -1\n",
    "    while not finished:\n",
    "\n",
    "        if count % 1000 == 0:\n",
    "            print('    eval process: ', count, ' of ', len(test_data), ' actions: ', (count / len(test_data) * 100.0), ' % in',\n",
    "                  (time.time() - st), 's')\n",
    "\n",
    "\n",
    "        crs = time.clock();\n",
    "        trs = time.time();\n",
    "\n",
    "        current_item = test_data[item_key][pos]\n",
    "        current_session = test_data[session_key][pos]\n",
    "        current_user = test_data[user_key][pos] # current_user = test_data[user_key][pos] if user_key is not None else -1\n",
    "        ts = test_data[time_key][pos]\n",
    "        rest = test_data[item_key][\n",
    "               pos + 1:offset_sessions[current_session_idx] + length_session[current_session_idx]].values\n",
    "\n",
    "        if prev_sid != current_session:\n",
    "            prev_sid = current_session\n",
    "            if hasattr(pr, 'predict_for_extended_model'):\n",
    "                past_items = pr.predict_for_extended_model(current_user)\n",
    "                for past_item in past_items:\n",
    "                    pr.predict_next(current_session, past_item, current_user, items_to_predict)  # to update the state for the current session, we do not need the predictions\n",
    "\n",
    "        if test_data['in_eval'][pos] == True:\n",
    "            for m in metrics:\n",
    "                if hasattr(m, 'start_predict'):\n",
    "                    m.start_predict(pr)\n",
    "\n",
    "        if pr.support_users():  # session-aware (e.g. hgru4rec)\n",
    "            preds = pr.predict_next(current_session, current_item, current_user, items_to_predict, timestamp=ts)\n",
    "        else:  # session-based (e.g. sknn)\n",
    "            preds = pr.predict_next(current_session, current_item, items_to_predict, timestamp=ts)  # without user_id\n",
    "\n",
    "        if test_data['in_eval'][pos] == True:\n",
    "            for m in metrics:\n",
    "                if hasattr(m, 'stop_predict'):\n",
    "                    m.stop_predict(pr)\n",
    "\n",
    "        preds[np.isnan(preds)] = 0\n",
    "         #  preds += 1e-8 * np.random.rand(len(preds)) #Breaking up ties\n",
    "        preds.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "        time_sum_clock += time.clock() - crs\n",
    "        time_sum += time.time() - trs\n",
    "        time_count += 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if test_data['in_eval'][pos] == True:\n",
    "            for m in metrics:\n",
    "                if hasattr(m, 'add_multiple'):\n",
    "                    m.add_multiple(preds, rest, for_item=current_item, session=current_session, position=position)\n",
    "                elif hasattr(m, 'add'):\n",
    "                    m.add(preds, rest[0], for_item=current_item, session=current_session, position=position)\n",
    "\n",
    "        pos += 1\n",
    "        position += 1\n",
    "\n",
    "        # check if we make prediction for all items of the current session (except the last one)\n",
    "        if pos + 1 == offset_sessions[current_session_idx] + length_session[current_session_idx]:\n",
    "            current_session_idx += 1 # start the next session\n",
    "\n",
    "            if current_session_idx == test_data[session_key].nunique(): # if we check all sessions of the test data\n",
    "                finished = True # finish the evaluation\n",
    "\n",
    "            # retrieve the index of the first interaction of the next session we want to iterate over\n",
    "            pos = offset_sessions[current_session_idx]\n",
    "            position = 0 # reset the first position of the first interaction in the session\n",
    "            # increment count because of the last item of the session (which we do not make prediction for)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    print('END evaluation in ', (time.clock() - sc), 'c / ', (time.time() - st), 's')\n",
    "    print('    avg rt ', (time_sum / time_count), 's / ', (time_sum_clock / time_count), 'c')\n",
    "    print('    time count ', (time_count), 'count/', (time_sum), ' sum')\n",
    "\n",
    "    res = []\n",
    "    for m in metrics:\n",
    "        if type(m).__name__ == 'Time_usage_testing':\n",
    "            res.append(m.result_second(time_sum_clock / time_count))\n",
    "            res.append(m.result_cpu(time_sum_clock / time_count))\n",
    "        else:\n",
    "            res.append(m.result())\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da6ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_hdf('../../session-aware_RC_2020/events.hdf', 'test')\n",
    "train_data = pd.read_hdf('../../session-aware_RC_2020/events.hdf', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6949e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = 'session_id'\n",
    "user_key = 'visitorid'\n",
    "item_key = 'itemid'\n",
    "time_key = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5d3a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39974,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_to_predict = train_data[item_key].unique()\n",
    "items_to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d18222",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = len(test_data)\n",
    "sessions = len(test_data[session_key].unique())\n",
    "count = 0\n",
    "print('START evaluation of ', actions, ' actions in ', sessions, ' sessions')\n",
    "\n",
    "\n",
    "time_sum = 0\n",
    "time_sum_clock = 0\n",
    "time_count = 0\n",
    "\n",
    "for m in metrics:\n",
    "    m.reset();\n",
    "\n",
    "# In case someone would try to run with both items=None and not None on the same model\n",
    "# without realizing that the predict function needs to be replaced\n",
    "# pr.predict = None\n",
    "\n",
    "items_to_predict = train_data[item_key].unique()\n",
    "\n",
    "# use the training sessions of the users in test_data to bootstrap the state of the user RNN\n",
    "test_users = test_data[user_key].unique()\n",
    "train_data = train_data[train_data[user_key].isin(test_users)].copy()\n",
    "\n",
    "# concatenate training and test sessions\n",
    "train_data['in_eval'] = False\n",
    "test_data['in_eval'] = True\n",
    "if pr.support_users(): # e.g. hgru4rec\n",
    "    if pr.predict_with_training_data():\n",
    "        test_data = pd.concat([train_data, test_data])\n",
    "\n",
    "test_data.sort_values([user_key, session_key, time_key], inplace=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "offset_sessions = np.zeros(test_data[session_key].nunique() + 1, dtype=np.int32)\n",
    "length_session = np.zeros(test_data[session_key].nunique(), dtype=np.int32)\n",
    "offset_sessions[1:] = test_data.groupby([user_key, session_key]).size().cumsum() # offset_sessions[1:] = test_data.groupby(session_key).size().cumsum()\n",
    "length_session[0:] = test_data.groupby([user_key, session_key]).size() # length_session[0:] = test_data.groupby(session_key).size()\n",
    "\n",
    "current_session_idx = 0\n",
    "# pos: to iterate over test data to retrieve the current session and it's first interaction\n",
    "pos = offset_sessions[current_session_idx] # index of the first element of the current session in the test data\n",
    "position = 0  # position (index) of the current element in the current session\n",
    "finished = False\n",
    "\n",
    "prev_sid = -1\n",
    "while not finished:\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print('    eval process: ', count, ' of ', len(test_data), ' actions: ', (count / len(test_data) * 100.0), ' % in',\n",
    "              (time.time() - st), 's')\n",
    "\n",
    "\n",
    "    crs = time.clock();\n",
    "    trs = time.time();\n",
    "\n",
    "    current_item = test_data[item_key][pos]\n",
    "    current_session = test_data[session_key][pos]\n",
    "    current_user = test_data[user_key][pos] # current_user = test_data[user_key][pos] if user_key is not None else -1\n",
    "    ts = test_data[time_key][pos]\n",
    "    rest = test_data[item_key][\n",
    "           pos + 1:offset_sessions[current_session_idx] + length_session[current_session_idx]].values\n",
    "\n",
    "    if prev_sid != current_session:\n",
    "        prev_sid = current_session\n",
    "        if hasattr(pr, 'predict_for_extended_model'):\n",
    "            past_items = pr.predict_for_extended_model(current_user)\n",
    "            for past_item in past_items:\n",
    "                pr.predict_next(current_session, past_item, current_user, items_to_predict)  # to update the state for the current session, we do not need the predictions\n",
    "\n",
    "    if test_data['in_eval'][pos] == True:\n",
    "        for m in metrics:\n",
    "            if hasattr(m, 'start_predict'):\n",
    "                m.start_predict(pr)\n",
    "\n",
    "    if pr.support_users():  # session-aware (e.g. hgru4rec)\n",
    "        preds = pr.predict_next(current_session, current_item, current_user, items_to_predict, timestamp=ts)\n",
    "    else:  # session-based (e.g. sknn)\n",
    "        preds = pr.predict_next(current_session, current_item, items_to_predict, timestamp=ts)  # without user_id\n",
    "\n",
    "    if test_data['in_eval'][pos] == True:\n",
    "        for m in metrics:\n",
    "            if hasattr(m, 'stop_predict'):\n",
    "                m.stop_predict(pr)\n",
    "\n",
    "    preds[np.isnan(preds)] = 0\n",
    "     #  preds += 1e-8 * np.random.rand(len(preds)) #Breaking up ties\n",
    "    preds.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "    time_sum_clock += time.clock() - crs\n",
    "    time_sum += time.time() - trs\n",
    "    time_count += 1\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if test_data['in_eval'][pos] == True:\n",
    "        for m in metrics:\n",
    "            if hasattr(m, 'add_multiple'):\n",
    "                m.add_multiple(preds, rest, for_item=current_item, session=current_session, position=position)\n",
    "            elif hasattr(m, 'add'):\n",
    "                m.add(preds, rest[0], for_item=current_item, session=current_session, position=position)\n",
    "\n",
    "    pos += 1\n",
    "    position += 1\n",
    "\n",
    "    # check if we make prediction for all items of the current session (except the last one)\n",
    "    if pos + 1 == offset_sessions[current_session_idx] + length_session[current_session_idx]:\n",
    "        current_session_idx += 1 # start the next session\n",
    "\n",
    "        if current_session_idx == test_data[session_key].nunique(): # if we check all sessions of the test data\n",
    "            finished = True # finish the evaluation\n",
    "\n",
    "        # retrieve the index of the first interaction of the next session we want to iterate over\n",
    "        pos = offset_sessions[current_session_idx]\n",
    "        position = 0 # reset the first position of the first interaction in the session\n",
    "        # increment count because of the last item of the session (which we do not make prediction for)\n",
    "        count += 1\n",
    "\n",
    "\n",
    "print('END evaluation in ', (time.clock() - sc), 'c / ', (time.time() - st), 's')\n",
    "print('    avg rt ', (time_sum / time_count), 's / ', (time_sum_clock / time_count), 'c')\n",
    "print('    time count ', (time_count), 'count/', (time_sum), ' sum')\n",
    "\n",
    "res = []\n",
    "for m in metrics:\n",
    "    if type(m).__name__ == 'Time_usage_testing':\n",
    "        res.append(m.result_second(time_sum_clock / time_count))\n",
    "        res.append(m.result_cpu(time_sum_clock / time_count))\n",
    "    else:\n",
    "        res.append(m.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6992b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_sessions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3a17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143b2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_sessions = np.zeros(test_data[session_key].nunique() + 1, dtype=np.int32)\n",
    "length_session = np.zeros(test_data[session_key].nunique(), dtype=np.int32)\n",
    "offset_sessions[1:] = test_data.groupby([user_key, session_key]).size().cumsum() # offset_sessions[1:] = test_data.groupby(session_key).size().cumsum()\n",
    "length_session[0:] = test_data.groupby([user_key, session_key]).size() # length_session[0:] = test_data.groupby(session_key).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f56f7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_session_idx = 0\n",
    "# pos: to iterate over test data to retrieve the current session and it's first interaction\n",
    "pos = offset_sessions[current_session_idx] # index of the first element of the current session in the test data\n",
    "position = 0  # position (index) of the current element in the current session\n",
    "finished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_session = test_data[session_key][pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab95aac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
