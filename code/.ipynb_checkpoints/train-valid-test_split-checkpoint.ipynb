{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Simon\\\\Desktop\\\\MA\\\\session-rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# inpath = '../../data/app-level/'\n",
    "# filename = 'data_app'\n",
    "# data = pd.read_csv(inpath + filename + '.csv')\n",
    "\n",
    "inpath = '../data/app-level/'\n",
    "filename = 'data_app'\n",
    "data = pd.read_csv(inpath + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign keys\n",
    "USER_KEY = 'userID'\n",
    "TIME_KEY = 'timestamp'\n",
    "ITEM_KEY = 'appID'\n",
    "SESSION_KEY = 'sessionID'\n",
    "# ITEM_KEY = 'usID'\n",
    "# SESSION_KEY = 'sentenceID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### workhorse functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, min_item_support=5, min_session_length=2, min_user_sessions=3,\n",
    "               drop_on=False, drop_off=False, drop_first=False, seq_drop_onoff=False):\n",
    "    '''\n",
    "    Preprocesses the dataframe by filtering out infrequent items, short sessions, and users with few sessions\n",
    "    -----\n",
    "        df: Pandas dataframe\n",
    "            Must contain the following columns: USER_KEY; ITEM_KEY; TIME_KEY; SESSION_KEY\n",
    "        drop_first: boolean\n",
    "            whether the first item of each session should be dropped\n",
    "        min_item_support: integer\n",
    "            minimum number of occurrences of an item (app) across all users and sessions for an item to be included\n",
    "        min_session_length: integer\n",
    "            minimum length (number of items) of a session for a session to be included\n",
    "        min_user_sessions: integer\n",
    "            minimum number of sessions per user for a user to be included\n",
    "    '''\n",
    "    if drop_first:\n",
    "        mask = df[ITEM_KEY].shift(-1).isin([1389, 1390]) # 1389=\"OFF_LOCKED\", 1390=\"OFF_UNLOCKED\"\n",
    "        df = df[~mask] # filter out the first item of each session, i.e., items PRECEDED by 1389 or 1390\n",
    "    if drop_on:\n",
    "        mask = df[ITEM_KEY].isin([1392, 1393])\n",
    "        df = df[~mask]\n",
    "    if drop_off:\n",
    "        mask = df[ITEM_KEY].isin([1389, 1390])\n",
    "        df = df[~mask]\n",
    "    if seq_drop_onoff:\n",
    "        mask = df[ITEM_KEY]==76202\n",
    "        df = df[~mask]\n",
    "    # min_item_support\n",
    "    df = df.groupby(ITEM_KEY).filter(lambda x: len(x) >= min_item_support)\n",
    "    # min_session_length\n",
    "    if df.groupby(SESSION_KEY)[SESSION_KEY].size().min() < min_session_length:\n",
    "        df = df.groupby(SESSION_KEY).filter(lambda x: len(x) >= min_session_length)\n",
    "    # min_user_sessions\n",
    "    user_sessions = df.groupby([USER_KEY])[SESSION_KEY].nunique()\n",
    "    mask = df[USER_KEY].apply(lambda x: user_sessions[x]) >= min_user_sessions\n",
    "    df = df[mask]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_last_session(df):\n",
    "    '''\n",
    "    Splits off the last session of a sequence of sessions for each user\n",
    "    -----\n",
    "        df: Pandas dataframe\n",
    "            Must contain the following columns: USER_KEY; ITEM_KEY; TIME_KEY; SESSION_KEY\n",
    "    '''\n",
    "    last_sessions = df[SESSION_KEY].groupby(df[USER_KEY]).transform('last')\n",
    "    train = df[df[SESSION_KEY]!=last_sessions]\n",
    "    test = df[df[SESSION_KEY]==last_sessions]\n",
    "    \n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_new_items(train, test):\n",
    "    '''\n",
    "    Filters out observations from a test set which do not appear in the corresponding training set\n",
    "    -----\n",
    "        train: Pandas dataframe\n",
    "            Training set; must contain the following columns: USER_KEY; ITEM_KEY; TIME_KEY; SESSION_KEY\n",
    "        test: Pandas dataframe\n",
    "            Test set; must contain the following columns: USER_KEY; ITEM_KEY; TIME_KEY; SESSION_KEY\n",
    "    '''\n",
    "    test = test[test[ITEM_KEY].isin(train[ITEM_KEY].unique())]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the above functions\n",
    "def split_data(df,\n",
    "               min_item_support, min_session_length, min_user_sessions,\n",
    "               USER_KEY, ITEM_KEY, TIME_KEY, SESSION_KEY,\n",
    "               drop_on=False, drop_off=False, drop_first=False, seq_drop_onoff=False):\n",
    "    df_preprocessed = preprocess(df,\n",
    "                                 min_item_support=min_item_support, min_session_length=min_session_length, min_user_sessions=min_user_sessions,\n",
    "                                 drop_on=drop_on, drop_off=drop_off, drop_first=drop_first, seq_drop_onoff=seq_drop_onoff)\n",
    "    train, test = split_last_session(df_preprocessed)\n",
    "    valid_train, valid_test = split_last_session(train)\n",
    "    test = filter_new_items(train, test)\n",
    "    valid_test = filter_new_items(valid_train, valid_test)\n",
    "    return (train, valid_train, valid_test, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### helper function for multiple windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a single item to a window (from 1,...,win) based on timestamp of first item of current session\n",
    "def assign_window(timestamp, cutoff_list):\n",
    "    num_windows = len(cutoff_list)\n",
    "    for i in range(num_windows):\n",
    "        if timestamp <= cutoff_list[i]:\n",
    "            window = i+1\n",
    "            break\n",
    "    return window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### apply preprocessing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_item_support = 5\n",
    "min_session_length = 20\n",
    "min_user_sessions = 3\n",
    "\n",
    "drop_on = False\n",
    "drop_off = False\n",
    "drop_first = False # should always be set to False if drop_on=True\n",
    "seq_drop_onoff = False # flag for sequence-level analysis to drop 'ON,OFF' sequences (tokens); set to False if filename is 'data_seq_drop_onoff_final'\n",
    "\n",
    "multiple_windows = False # flag for multiple windows\n",
    "win = 5 # only needed if multiple_windows=True\n",
    "\n",
    "outpath = '../data/app-level/multiple/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiple_windows:\n",
    "    \n",
    "    ts_min = data.timestamp.min()\n",
    "    ts_max = data.timestamp.max()\n",
    "    win_timespan = (ts_max-ts_min)/win\n",
    "    win_cutoffs = [ts_min+(i+1)*win_timespan for i in range(win)]\n",
    "    \n",
    "    # create new column containing timestamp from first item of each session for each item of the session\n",
    "    data['window'] = data['timestamp'].groupby(data[SESSION_KEY]).transform('first')\n",
    "\n",
    "    # based on timestamp from first item, assign the entire session to one of the win windows\n",
    "    # to do so, apply assign_window to entire column \"window\"\n",
    "    # this way, we never split up sessions\n",
    "    data['window'] = data['window'].apply(lambda x: assign_window(x, win_cutoffs))\n",
    "    \n",
    "    for i in range(win):\n",
    "        name = 'events' + '-' + str(i+1) # set up dataset name, e.g., data_1 corresponding to windows 1\n",
    "        df = data[data.window==i+1].drop('window',axis=1) # choose one single window only\n",
    "        train, valid_train, valid_test, test = split_data(df,\n",
    "                                                         min_item_support, min_session_length, min_user_sessions,\n",
    "                                                         USER_KEY, ITEM_KEY, TIME_KEY, SESSION_KEY,\n",
    "                                                         drop_on=drop_on, drop_off=drop_off, drop_first=drop_first,\n",
    "                                                         seq_drop_onoff=seq_drop_onoff)\n",
    "        # save output to hdf files\n",
    "        if min_session_length > 2:\n",
    "            outname = outpath + str(name) + '-min' + str(min_session_length)\n",
    "        else:\n",
    "            outname = outpath + str(name)\n",
    "        if drop_on:\n",
    "            outname += '-drop_on'\n",
    "        if drop_off:\n",
    "            outname += '-drop_off'\n",
    "        if drop_first:\n",
    "            outname += '-drop_first'\n",
    "        if seq_drop_onoff:\n",
    "            outname += '-seq_drop_onoff'\n",
    "        if filename == 'data_seq_drop_onoff_final':\n",
    "            outname += '-seq_drop_onoff_all'\n",
    "        outname += '.hdf'\n",
    "        \n",
    "        train.to_hdf(outname, key='train', mode='w') # create new file (to avoid adding to existing file)\n",
    "        valid_test.to_hdf(outname, key='valid_test', mode='a')\n",
    "        valid_train.to_hdf(outname, key='valid_train', mode='a')\n",
    "        test.to_hdf(outname, key='test', mode='a')\n",
    "        \n",
    "else:\n",
    "    train, valid_train, valid_test, test = split_data(data,\n",
    "                                                      min_item_support, min_session_length, min_user_sessions,\n",
    "                                                      USER_KEY, ITEM_KEY, TIME_KEY, SESSION_KEY,\n",
    "                                                      drop_on=drop_on, drop_off=drop_off, drop_first=drop_first,\n",
    "                                                      seq_drop_onoff=seq_drop_onoff)\n",
    "    if min_session_length > 2:\n",
    "        outname = outpath + 'events' + '-min' + str(min_session_length)\n",
    "    else:\n",
    "        outname = outpath + 'events'\n",
    "    if drop_on:\n",
    "        outname += '-drop_on'\n",
    "    if drop_off:\n",
    "        outname += '-drop_off'\n",
    "    if drop_first:\n",
    "        outname += '-drop_first'\n",
    "    if seq_drop_onoff:\n",
    "        outname += '-seq_drop_onoff'\n",
    "    if filename == 'data_seq_drop_onoff_final':\n",
    "        outname += '-seq_drop_onoff_all'\n",
    "    outname += '.hdf'\n",
    "    \n",
    "    test.to_hdf(outname, key='test', mode='w') # create new file (to avoid adding to existing file)\n",
    "    train.to_hdf(outname, key='train', mode='a')\n",
    "    valid_test.to_hdf(outname, key='valid_test', mode='a')\n",
    "    valid_train.to_hdf(outname, key='valid_train', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
