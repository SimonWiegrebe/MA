{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7e1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f21de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Simon\\\\Desktop\\\\MA\\\\session-rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b23917",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_onoff = False\n",
    "min20 = False # only for app-level\n",
    "min20_test = True # only for app-level\n",
    "# datatypes = ['app-level', 'sequence-level']\n",
    "# datatypes = ['sequence-level']\n",
    "datatypes = ['app-level'] # for min20 analysis: only app-level\n",
    "windows = [1,2,3,4,5]\n",
    "# windows = 'single'\n",
    "\n",
    "USER_KEY = 'userID'\n",
    "TIME_KEY = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "623447e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to only include test sessions with minimum length 20\n",
    "def only_min20(df):\n",
    "    df = df.groupby(SESSION_KEY).filter(lambda x: len(x) >= 20)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f94109b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datatype in datatypes:\n",
    "    if datatype == 'app-level':\n",
    "        ITEM_KEY = 'appID'\n",
    "        SESSION_KEY = 'sessionID'\n",
    "        onoff_key = 'drop_on-drop_off'\n",
    "        min20_key = 'min20'\n",
    "        min20_test_key = 'min20_test'\n",
    "    else:\n",
    "        ITEM_KEY = 'usID'\n",
    "        SESSION_KEY = 'sentenceID'\n",
    "        onoff_key = 'seq_drop_onoff_all'\n",
    "    \n",
    "    if windows == 'single':\n",
    "        path_in = '../data/' + str(datatype) + '/single/'\n",
    "        file_in = 'events'\n",
    "        if min20:\n",
    "            file_in += '-' + str(min20_key)\n",
    "        if exclude_onoff:\n",
    "            file_in += '-' + str(onoff_key) \n",
    "        file_in += '.hdf'\n",
    "\n",
    "        file_out = 'single'\n",
    "        if min20:\n",
    "            file_out += '-' + str(min20_key)\n",
    "        if min20_test:\n",
    "            file_out += '-' + str(min20_test_key)\n",
    "        file_out += '.hdf'\n",
    "\n",
    "        if min20_test:\n",
    "            path_out = 'data/testing'\n",
    "            if exclude_onoff:\n",
    "                path_out += '_onoff'\n",
    "            path_out += '/' + str(datatype) + '/single/'\n",
    "            dataset_test = only_min20(pd.read_hdf(path_in + file_in, 'test'))\n",
    "            dataset_train = pd.read_hdf(path_in + file_in, 'train') \n",
    "            dataset_test.to_hdf(path_out + file_out, key='test', mode='w')\n",
    "            dataset_train.to_hdf(path_out + file_out, key='train', mode='a')\n",
    "        else:            \n",
    "            for split in ['test', 'train']:\n",
    "                path_out = 'data/testing'\n",
    "                if exclude_onoff:\n",
    "                    path_out += '_onoff'\n",
    "                path_out += '/' + str(datatype) + '/single/'\n",
    "                dataset = pd.read_hdf(path_in + file_in, split)\n",
    "                if split == 'test': mode = 'w' # create new file for 'test', which is the first split (to avoid adding to existing file)\n",
    "                else: mode = 'a' # append all other splits\n",
    "                dataset.to_hdf(path_out + file_out, key=split, mode=mode)        \n",
    "\n",
    "    else:    \n",
    "        for window in windows:    \n",
    "            path_in = '../data/' + str(datatype) + '/multiple/'\n",
    "            file_in = 'events-' + str(window)\n",
    "            if min20:\n",
    "                file_in += '-' + str(min20_key)\n",
    "            if exclude_onoff:\n",
    "                file_in += '-' + str(onoff_key) \n",
    "            file_in += '.hdf'\n",
    "\n",
    "            file_out = 'window_' + str(window)\n",
    "            if min20:\n",
    "                file_out += '-' + str(min20_key)\n",
    "            if min20_test:\n",
    "                file_out += '-' + str(min20_test_key)\n",
    "            file_out += '.hdf'\n",
    "\n",
    "            if min20_test: # no tuning, only testing\n",
    "                path_out = 'data/testing'\n",
    "                if exclude_onoff:\n",
    "                    path_out += '_onoff'\n",
    "                path_out += '/' + str(datatype) + '/multiple/'\n",
    "                dataset_test = only_min20(pd.read_hdf(path_in + file_in, 'test'))\n",
    "                dataset_train = pd.read_hdf(path_in + file_in, 'train') \n",
    "                dataset_test.to_hdf(path_out + file_out, key='test', mode='w')\n",
    "                dataset_train.to_hdf(path_out + file_out, key='train', mode='a')\n",
    "            else:          \n",
    "                for split in ['valid_test', 'valid_train']:\n",
    "                    path_out = 'data/tuning'\n",
    "                    if exclude_onoff:\n",
    "                        path_out += '_onoff'\n",
    "                    path_out += '/' + str(datatype) + '/multiple/'\n",
    "                    dataset = pd.read_hdf(path_in + file_in, split)\n",
    "                    if split == 'valid_test': mode = 'w' # create new file for 'valid_test', which is the first split (to avoid adding to existing file)\n",
    "                    else: mode = 'a' # append all other splits\n",
    "                    new_split = split.split('_')[1]\n",
    "                    dataset.to_hdf(path_out + file_out, key=new_split, mode=mode)\n",
    "\n",
    "                for split in ['test', 'train']:\n",
    "                    path_out = 'data/testing'\n",
    "                    if exclude_onoff:\n",
    "                        path_out += '_onoff'\n",
    "                    path_out += '/' + str(datatype) + '/multiple/'\n",
    "                    dataset = pd.read_hdf(path_in + file_in, split)\n",
    "                    if split == 'test': mode = 'w' # create new file for 'test', which is the first split (to avoid adding to existing file)\n",
    "                    else: mode = 'a' # append all other splits\n",
    "                    dataset.to_hdf(path_out + file_out, key=split, mode=mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
