{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c662f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d9994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/sequence-level/data_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27865054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.read_csv('../../data/sequence-level/data_seq_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54664ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526181081369308"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of sequences of minimum length 20\n",
    "data_final.groupby('sentenceID').filter(lambda x: len(x) >= 20).sentenceID.nunique()/data_final.sentenceID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ca16d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3844150, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a019435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "      <th>category_name</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>app_name</th>\n",
       "      <th>sessionID</th>\n",
       "      <th>category_list</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_freq</th>\n",
       "      <th>seq_duration</th>\n",
       "      <th>usID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01ADD53B</td>\n",
       "      <td>1.511423e+09</td>\n",
       "      <td>2017-11-23 07:44:19.952000000</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>ON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>0.338</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01ADD53B</td>\n",
       "      <td>1.511423e+09</td>\n",
       "      <td>2017-11-23 07:44:20.289999872</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>0.338</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>01ADD53B</td>\n",
       "      <td>1.511424e+09</td>\n",
       "      <td>2017-11-23 08:02:01.137000192</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>12.802</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>01ADD53B</td>\n",
       "      <td>1.511424e+09</td>\n",
       "      <td>2017-11-23 08:02:13.938999808</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>12.802</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>01ADD53B</td>\n",
       "      <td>1.511424e+09</td>\n",
       "      <td>2017-11-23 08:02:51.140999936</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>ON</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>ON,INBOX,ON,OFF</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>164.784</td>\n",
       "      <td>16586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844145</th>\n",
       "      <td>310</td>\n",
       "      <td>FEB02F63</td>\n",
       "      <td>1.515952e+09</td>\n",
       "      <td>2018-01-14 17:53:14.138000128</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844294</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>9.706</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844146</th>\n",
       "      <td>310</td>\n",
       "      <td>FEB02F63</td>\n",
       "      <td>1.515952e+09</td>\n",
       "      <td>2018-01-14 17:53:32.335000064</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>ON</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844295</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>9.891</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844147</th>\n",
       "      <td>310</td>\n",
       "      <td>FEB02F63</td>\n",
       "      <td>1.515952e+09</td>\n",
       "      <td>2018-01-14 17:53:42.226000128</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844295</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>9.891</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844148</th>\n",
       "      <td>310</td>\n",
       "      <td>FEB02F63</td>\n",
       "      <td>1.515953e+09</td>\n",
       "      <td>2018-01-14 17:56:59.348000000</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>ON</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844296</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>9.538</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844149</th>\n",
       "      <td>310</td>\n",
       "      <td>FEB02F63</td>\n",
       "      <td>1.515953e+09</td>\n",
       "      <td>2018-01-14 17:57:08.885999872</td>\n",
       "      <td>SCREEN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844296</td>\n",
       "      <td>ON,OFF</td>\n",
       "      <td>2</td>\n",
       "      <td>367835.0</td>\n",
       "      <td>9.538</td>\n",
       "      <td>76202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3844150 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID    userId     timestamp                           date  \\\n",
       "0             1  01ADD53B  1.511423e+09  2017-11-23 07:44:19.952000000   \n",
       "1             1  01ADD53B  1.511423e+09  2017-11-23 07:44:20.289999872   \n",
       "2             1  01ADD53B  1.511424e+09  2017-11-23 08:02:01.137000192   \n",
       "3             1  01ADD53B  1.511424e+09  2017-11-23 08:02:13.938999808   \n",
       "4             1  01ADD53B  1.511424e+09  2017-11-23 08:02:51.140999936   \n",
       "...         ...       ...           ...                            ...   \n",
       "3844145     310  FEB02F63  1.515952e+09  2018-01-14 17:53:14.138000128   \n",
       "3844146     310  FEB02F63  1.515952e+09  2018-01-14 17:53:32.335000064   \n",
       "3844147     310  FEB02F63  1.515952e+09  2018-01-14 17:53:42.226000128   \n",
       "3844148     310  FEB02F63  1.515953e+09  2018-01-14 17:56:59.348000000   \n",
       "3844149     310  FEB02F63  1.515953e+09  2018-01-14 17:57:08.885999872   \n",
       "\n",
       "        activity category_name  sequence_number app_name  sessionID  \\\n",
       "0         SCREEN            ON              1.0      NaN          1   \n",
       "1         SCREEN           OFF              1.0      NaN          1   \n",
       "2         SCREEN            ON              2.0      NaN          2   \n",
       "3         SCREEN           OFF              2.0      NaN          2   \n",
       "4         SCREEN            ON              3.0      NaN          3   \n",
       "...          ...           ...              ...      ...        ...   \n",
       "3844145   SCREEN           OFF           1512.0      NaN     844294   \n",
       "3844146   SCREEN            ON           1513.0      NaN     844295   \n",
       "3844147   SCREEN           OFF           1513.0      NaN     844295   \n",
       "3844148   SCREEN            ON           1514.0      NaN     844296   \n",
       "3844149   SCREEN           OFF           1514.0      NaN     844296   \n",
       "\n",
       "           category_list  seq_length  seq_freq  seq_duration   usID  \n",
       "0                 ON,OFF           2  367835.0         0.338  76202  \n",
       "1                 ON,OFF           2  367835.0         0.338  76202  \n",
       "2                 ON,OFF           2  367835.0        12.802  76202  \n",
       "3                 ON,OFF           2  367835.0        12.802  76202  \n",
       "4        ON,INBOX,ON,OFF           4       9.0       164.784  16586  \n",
       "...                  ...         ...       ...           ...    ...  \n",
       "3844145           ON,OFF           2  367835.0         9.706  76202  \n",
       "3844146           ON,OFF           2  367835.0         9.891  76202  \n",
       "3844147           ON,OFF           2  367835.0         9.891  76202  \n",
       "3844148           ON,OFF           2  367835.0         9.538  76202  \n",
       "3844149           ON,OFF           2  367835.0         9.538  76202  \n",
       "\n",
       "[3844150 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4c0018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367835"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_final.usID == 76202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b16f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_item_support = 5\n",
    "min_session_length = 2\n",
    "min_user_sessions = 3\n",
    "drop_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "628255e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_KEY = 'userID'\n",
    "TIME_KEY = 'timestamp'\n",
    "ITEM_KEY = 'usID'\n",
    "SESSION_KEY = 'sentenceID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "022cc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "data = data[data['seq_freq']>=N].groupby(['sessionID']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b86ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = pd.to_datetime(data.timestamp.min(), unit='s').date()\n",
    "end_day = pd.to_datetime(data.timestamp.max(), unit='s').date()\n",
    "day_range = pd.date_range(start_day, end_day, freq='D')\n",
    "\n",
    "# helper list (same length as data) containing the day\n",
    "user_day = data['userID'].astype(str).str.zfill(3) + '_' + pd.to_datetime(data['timestamp'], unit='s').apply(lambda x: x.date()).astype(str)\n",
    "\n",
    "sentence_mapping = dict([(y,x+1) for x,y in enumerate(sorted(set(user_day)))])\n",
    "sentence_indexes = [sentence_mapping[x] for x in user_day]\n",
    "\n",
    "data['sentenceID'] = sentence_indexes\n",
    "data['sentence_freq'] = data.groupby([SESSION_KEY])[SESSION_KEY].transform('size')\n",
    "\n",
    "session_lengths = data.groupby('sentenceID').sentenceID.count()\n",
    "q1_eps = np.quantile(session_lengths.values, 0.25)\n",
    "median_eps = np.quantile(session_lengths.values, 0.50)\n",
    "q3_eps = np.quantile(session_lengths.values, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba413d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sequence-level analysis, user sequences are tokens (events) and daily concatenations thereof are sentences (sessions).\n",
      "For sequence-level analysis, only tokens with frequency of at least 10 were included\n",
      "The sequence-level data contains a total of:\n",
      "     - 9377 sentences\n",
      "     - 234 sentences with only one token (excluded during data split due to minimum session length of 2)\n",
      "     - 720379 tokens\n",
      "     - 2454 unique tokens\n",
      "1st quartile of events per session: 34.0\n",
      "median number of events per session: 66.0\n",
      "3rd quartile of events per session: 106.0\n"
     ]
    }
   ],
   "source": [
    "print('For sequence-level analysis, user sequences are tokens (events) and daily concatenations thereof are sentences (sessions).')\n",
    "print('For sequence-level analysis, only tokens with frequency of at least ' + str(N) + ' were included')\n",
    "print('The sequence-level data contains a total of:')\n",
    "print('     - ' + str(data[SESSION_KEY].nunique()) + ' sentences')\n",
    "print('     - ' + str(sum(data.sentence_freq==1)) + ' sentences with only one token (excluded during data split due to minimum session length of 2)')\n",
    "print('     - ' + str(data.shape[0]) + ' tokens')\n",
    "print('     - ' + str(data.usID.nunique()) + ' unique tokens')\n",
    "print('1st quartile of events per session: ' + str(round(q1_eps, 2)))\n",
    "print('median number of events per session: ' + str(round(median_eps, 2)))\n",
    "print('3rd quartile of events per session: ' + str(round(q3_eps, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3699cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentenceID\n",
       "1        60\n",
       "2        57\n",
       "3        12\n",
       "4        15\n",
       "5        54\n",
       "       ... \n",
       "9373     12\n",
       "9374      2\n",
       "9375     62\n",
       "9376    105\n",
       "9377     57\n",
       "Name: usID, Length: 9377, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('sentenceID').sentenceID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "123e454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sequence-level analysis, we have: \n",
      "     - 720379 sentences of length >= 1\n",
      "     - 720145 sentences of length >= 2\n",
      "     - 719851 sentences of length >= 3\n",
      "     - 719608 sentences of length >= 4\n",
      "     - 719376 sentences of length >= 5\n",
      "     - 719076 sentences of length >= 6\n",
      "     - 718692 sentences of length >= 7\n",
      "     - 718342 sentences of length >= 8\n",
      "     - 717894 sentences of length >= 9\n",
      "     - 717498 sentences of length >= 10\n",
      "     - 713946 sentences of length >= 15\n",
      "     - 708961 sentences of length >= 20\n",
      "     - 634510 sentences of length >= 50\n",
      "     - 397801 sentences of length >= 100\n",
      "     - 93476 sentences of length >= 200\n",
      "     - 3830 sentences of length >= 500\n",
      "Clearly, most of the sentences are not short. Therefore, restricting ourselves to sentences of a certain minimum length, say, 20, would not have much of an impact.\n",
      "Based on this, language modeling techniques should work reasonably well.\n",
      "Furthermore, we might expect LM techniques to perform rather well on predicting tokens in higher positions.\n"
     ]
    }
   ],
   "source": [
    "print('For sequence-level analysis, we have: ')\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,15,20,50,100,200,500]:\n",
    "    print('     - ' + str(sum(data.sentence_freq>=i)) + ' sentences of length >= ' + str(i))\n",
    "print('Clearly, most of the sentences are not short. Therefore, restricting ourselves to sentences of a certain minimum length, say, 20, would not have much of an impact.')\n",
    "print('Based on this, language modeling techniques should work reasonably well.')\n",
    "print('Furthermore, we might expect LM techniques to perform rather well on predicting tokens in higher positions.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
